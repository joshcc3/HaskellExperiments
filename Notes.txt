<LINK 0
   MONAD LAWS:

   return a >>= k  =  k a
   m >>= return    =  m
   m >>= (\x -> k x >>= h)  =  (m >>= k) >>= h
 
   fmap f xs  =  xs >>= return . f  =  liftM f xs
>


<LINK 1

   Constructing the state monad. The state monad is simply a monad
   that holds a state function. A state function is a function that
   takes a state and generates a value and a new state out of the
   state.
   The state monad must evidently be a functor. A functor is something
   that relates categories. It relates the Hask category with the
   St category a sub category of Hask. It is the category that is
   parameterized by a state. It maps tyeps from Hask to types in State.
   It maps morphisms in Hask, to morphisms in State. That is it provides
   a computational context for values.
>

<LINK 2
 the state constructor State :: (s -> (a,s)) -> St s a
 that is it takes a function that takes a state and produces
 a value and an updated state.
>

<LINK 3
 create a type class for types that define well founded orderings on instances
>

<LINK 4
   in our case of computing resources, the resource is a sequence of
   commands. The value produced by the sequence of commands is a state function
   or a binding of variables to values the type Env
   what we want to do is given some resources and a context for consuming these
   resources compute the result
>

<LINK 5
 the step function performs a (small step?) operation on the commands
>

<LINK 6
 What happens in the bind function is that the initial context for resource
 utilization if by applying the resource supplied to the original context
 results in a value, we simply feed this value to the function that takes
 takes values and generates resource contexts out of them, that is the
 resource context depends on the value of another computation on a resource
 much like in function calls.
 If the result of the first operation is a suspended computation because the
 resources ran out, then we just return the result - the resource we have
 uptil now and the suspended computation is now the original suspended computation
 bound into the subsequent computation denoted by f
>


<LINK 7
 Working
   (+) :: (MbT (Rdr Env) Exp) -> (MbT (Rdr Env) Exp) -> (MbT (Rdr Env) Exp)

   abs :: (MbT (Rdr Env) Exp) -> (MbT (Rdr Env) Exp)
   abs (MaybeT readerM) = MaybeT (Reader (\env -> lift (abs) (runReader readerM env)))



eval :: Exp -> Env -> (Maybe Int, Env)
eval (Var var) env
 = (lookup var env, env)
 = (,) (lookup var env) env

let (lookup var) = g
    (,)          = h

eval env = h (g env) env
eval :: (Int -> Env -> (Int, Env)) -> (Env -> Int) -> (Int, Env)

Thus in this case the reader monad is environment

eval h g env = h (g env) env

instance Monad (-> r) where
(>>=) :: m a -> (a -> m b) -> m b
(>>=) :: (r -> a) -> (a -> r -> b) -> r -> b

f :: (a -> b) ->  (b -> a -> c) -> a -> c
a = r, b = a, c = b
f :: (r -> b) -> (a -> r -> b) -> r -> b

f y = h (g y) y = (>>=) g h


 = (>>=) (lookup var) (,) env

eval (Var var) = (>>=) (lookup var) (,)

Thus eval is just bind with a specific function for h and g
thus


>

<LINK 8
  We are going to try and build a resourcefule computation.
  The resourceful computation is going to get some resources and proceed
  with computation until all the resources are finished.
  data RComp r a = R (r -> (r, Either a (RComp r a)))


instance Monad (RComp r) where
--  return :: a -> RComp a
   return a = R (\c -> (c, Left a))

--   (>>=) :: RComp a -> (a -> RComp b) -> RComp b
   (>>=) (R rf) (f) = R (\c -> func (rf c) f)
     where
--func :: (Com, Either a (RComp a)) -> (a -> RComp b)->(Com, Either b (RComp b))
       func (c, Left v) f = let (R rf') = (f v) in rf' c
       func (c, Right suspended) f = (c, Right (suspended >>= f))

  This monad wraps a function that takes a resource and produces a new value
  using that resource.

  As the simplest operation we are simply going to let our resources be a number
  of computation steps remaining. The value that our function produces will be
  an integer.

>

<LINK 9
  What this function says is that if we have more resources then take a step and return
  the result passed to us. This function seems to be acting as return.
>

<LINK 10
  The state monad is a context for COMPUTATION. The main thing is the computation. The
  monad provides a mechanism for supplying different contexts to the computation. The
  of what a context is, is not specified leaving it up to the specific monad to decide
  exactly what context it will give the computation it is holding. The real power of the
  monad comes in its ability to chain computations together.
  Specifically for the state monad, the context it supplies to the computation it holds
  is a value. The result of the computation is also a value allowing the state computation
  to chain values.
  For the maybe monad, the computation is, if something has failed, then no matter the
  context we have failed. Otherwise the context is the identity function. Thus it houses
  no actual computation other than the notion o failure which is even more awesome.

  Monads are the design patterns of haskell.
  The list monad is interesting. It too does not house any computation. Thus we were wrong
  previously, housing computation is not the only way you can provide a context for computaion.
  A list is provides a context for computation. That is computation performed on the Lst monad may
  be seen as
  The way to explain it is to imagine computation as an entity. Computation works on instances of types.
  in order to augment the ability of computation without modifying the ability of computation we wrap what
  ot operates on  - the instances of types and

>

< LINK 11
 im stupid. Of course there is some intelligence in designing the monads
 what happens is that we wnat to transform a normal stateless monad
 into a stateful monad. We can't access the inner state of the monad.
 The state exists beyond the monad.

>


<LINK 12

Type Algebra: 
 Either a b  has the same properties as  a + b, that is it is commutative, associative, (^) distributes over it replacing plus with multiply, multiplication distributes over it.

(a, b)  has the same properties as  a*b

a -> r  has the same properties as  r^a  -- with respect to the other operations

Algebraic operators are defined primarily by their properties and their properties in relation
to other operators. The semantics they carry differ from set to set.

The elements of our set are primitive types, algaebraic data types and functions which can also be seen as an algaebraic data types.

The Either operator takes two types and gives either one of them. We say that it is analogous to (+) defined over the natural numbers. However its semantics do not seem to overlap. However their properties are identical. Either is commutative, associative as well as the afore mentioned properties.

Similarly for the other two operators their properties line up with the others. So an algebra is simply a set with some operators defined on the elements. (notice the boolean 'and' and 'or' are also algaebraic operators. They dont seem to behave exactly like the (+) and (*) operators though)

The semantics of how Either, (,) and (^) emerge when we observe them in action. Either is simply a type that will give one of its types no matter how many nested eithers. This makes it commutative and associative. 
(,)  is a type that means you take both of the types presented.
(^) means give the exponent you have the base.
interestin behaviour arises when you combine the two, or when function definitions can be expressed in terms of the other operators. 
(a -> r) -> (b -> r) -> r, is equivalent to (a -> r, b -> r) -> r, HUH?
Think about it, how would you read the function, given an (a -> r) and a (b -> r) i get an r.

>


<LINK 13
  The continuation passing style takes the function to be evaluated next as its argument. It passes the result to the next function It also allows for non local transfers and early exit of a method. In fact it allows you to suspend functions somehow. Should check this out. Lazy evaluation is mainly supported by  the continuation monad.
FOllowing the continuation passing style, a continuation simply holds the future of the function. When we say future of a function we mean that a function has finished the computation it wishes to perform produces an intermediate value 'a', it takes as an argument the function to be evaluated next and gives the function its intermediate value. This is very similiar to what we have been doing all this time with the chaining computations. We have a computation and we fix the next computation by chaining it together with the result of the previous computation. Thus fixing the next function to be used in the computation that uses the result of the previous computation.
The continuation monad holds within it the future of a function. That is it holds within it a suspended computation. Giving this suspended computation a future - in the form of a function that takes the value computed so far and returns a result. In order to terminate such a chain we can simply use 'id' as the last function. 
>

<LINK 14
  Interesting idea would be to stop using specific monads and try and come up wiht computations that simply need the general properties of monads i.e. computations that can be chained. And where the chaining must be associative. Equally interesting are the idea of Monoids. Monoids are monads that consist of a type, an identity or zero element and a binary operator. They must obey the laws of the identity element. Also the binary operator should be associative. 
>

< LINK 15
Can use symbols for your own operators
(<>) :: Int -> Int -> Int
(<>) = (+)
{-# INLINE (<>) #-}
infixr 6 <>
>


<
 LINK 16
NOTE: This must be read in tandem with the callCC code otherwise it might be weird.
'func' is a suspended computation that is waiting for a continuation. the argument to func 'f' is the continuation. the suspended computation func is expecting an f and it will give a new continuation 'Ct r a'
'arg' is also a suspended computation. It is waiting for a function that will go from an 'a' to a 'Ct r b' and will give the final continuation.
So the action that func does is to get a continuation somehow, lets call it _____ and then give to this continuation 'f'.
Now comes the interesting part with the _______. The _____ is the argument applied to g. Thus when we use callCC we must give it a function. This function should take as an argument the continutation we want. g Becomes that continuation.
g is a function that returns a continuation that is waiting for a function, but never uses that function. It goes to the originally supplied continuation.
arg :: ((a -> Cont r b) -> Cont r a)
func :: (a -> r) -> r
f :: a -> r
g :: a -> Cont r b
h :: (b -> r) -> r
bF :: b -> r
a

>



<

Recently undertook developing a parser EDSL. Although it's an NFA it illustrates in italic cursive a few of Haskell's strengths. The elegance and power of Haskell EDSLs, the guidance types provide in programming and code reuse.

So first lets define what we want to build. A parser is a program that analyzes a string of tokens based on a formal grammar. Thus we want to expose a grammar to the user and something that consumes sentences in the grammar and spits out an answer.
 
We'll use regular expressions for that grammar, our interface will thus comprise:
match :: Token -> Result -> Parser Token Result
concatenate :: Parser Token Result -> Parser Token Result -> Parser Token Result
alternate :: Parser Token Result -> Parser Token Result -> Parser Token Result
step :: (Token,  Parser Token Result) -> (Either Error Result, Either Err (Either (Parser Token Result) Result))

The match combinator should, if it matches a token output the result or the error otherwise.
Concatenate should join two regular expressions end to end, such that it doesn't succeed until both succeed. Alternate should succeed if any of its operands succeed and if both succeed probably take the monoidal sum of them. In fact we could proably replace them with the predicates for success and failure. This gives us all the interesting properties of boolean algebra
Let's play a little with these functions and see what sort of behavior we'd expect from them.


step a (match a r) =  (Right r, Right (Right r))
step b (match a r) = (Left err, Left err)
step a (match a r  `concatenate` match b r') = (Right r, Right (Left (match b r)))

The above is fairly standard behavior we'd expect from step, it's just deconstructing a stream with support for error handling and stream termination. 

Left x  `concatenate` p = Left x 
p `concatenate` Left x = Left x -- Absorption
p `concatenate` (p' `concatenate` p'') = (p `concatenate` p') `concatenate` p'' -- Associativity

Left x `alternate` p = p -- Identity
p `alternate` (p' `alternate` p'') = (p `alternate` p') `alternate` p'' -- Associativity
p `alternate` p' = p' `alternate` p -- Commutativity

Distributivity
p `concatenate` (p' `alternate` p'') = (p `concatenate` p' `alternate` p `concatenate` p'')
p `alternate` (p' `concatenate` p'') = (p `alternate` p') `concatenate` (p `alternate` p'')

This is in captured by the MonadPlus type class with mplus as alternate and (>>=) as concatenate. 
Thus all we need to do to create our parser is simply add handling for the input and we are done. Generation of input must be a seperate concern from the querying of input. Since we are developing a non-deterministic parser we will have to jump about in the stream. Thus our input will consist of a stream generator and our position in the stream. Zippers are excellent for keeping track of positions in the stream. A parser must thus track the current state of the input. 
The english naturally describes the type for the parser 
type Zipper i = ([i], i, [i])
type St i = (Zipper i, Producer i)
type Parser i o = MonadPlus m => StateT (St i) m o 
 
Each of the above definitions write themselves. As a point of case, in general since we develop context independent grammars, the applicative instance is sufficient.

However regular expressions derive their power from the * operator. * can be seen as matching, 0 or more occurences of a regex, adding this functionality will be discussed in the next post.

<

m* = Nothing `alternate` m `alternate` (m `concatenate m) `alternate` (m `concatenate m `concatenate m) ...
first attempt at defining that..
m* = [foldl concatenate (replicate n m) | x <- [1..]]
but wait, this wont work because in order to make the first step it must check the infinite disjunctions.
We use our distributivity to factorize and obtain:
m* = Nothing `alternate` m `concatenate` (Nothing `alternate` m `concatenate` (...
Here m* is the fixed point of the above hence we have the equation, 
m* = Nothing `alternate` m `concatenate` m*
However trying this out doesn't seem to work either. This is because
Thus we require interleaving of the output, which is achieved through the logict interface. Our code was extensible enough that we could add the effects we wanted with ease.  
>

<
Now that we've created our framework, it's time to start writing parsers. The lexer will be our first parser for which we generate these tokens. Now to develop a parser on the lexixcal input. This parses the stream and its an edsl sp we can add type information to restrict the parser etc.
>

<
Prisms: Prisms are the next interesting thing after Isos. We slowly give each next layer more power. The profunctor is not just a profunctor but also choice. Choice gives us two new functions left' :: p a b -> p (Either a c) (Either b c) and right' :: p a b -> Either (c a) (c b). This allows us to create a dependency on the
>
